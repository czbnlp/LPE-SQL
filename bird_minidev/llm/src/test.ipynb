{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取zero-shot的结果\n",
    "from utils import save_data\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def package_sqls(\n",
    "    sql_path, db_root_path, engine, sql_dialect=\"SQLite\", mode=\"gpt\", data_mode=\"dev\"\n",
    "):\n",
    "    clean_sqls = []\n",
    "    db_path_list = []\n",
    "    if mode == \"gpt\":\n",
    "        # use chain of thought\n",
    "        sql_data = json.load(path)\n",
    "        for _, sql_str in sql_data.items():\n",
    "            if type(sql_str) == str:\n",
    "                sql, db_name = sql_str.split(\"\\t----- bird -----\\t\")\n",
    "            else:\n",
    "                sql, db_name = \" \", \"financial\"\n",
    "            clean_sqls.append(sql)\n",
    "            db_path_list.append(db_root_path + db_name + \"/\" + db_name + \".sqlite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json(dir):\n",
    "    with open(dir, \"r\") as j:\n",
    "        contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "def compute_acc_by_diff(exec_results, diff_json_path, results_path, metric=\"EX\"):\n",
    "    num_queries = len(exec_results)\n",
    "    contents = load_json(diff_json_path)\n",
    "    simple_results, moderate_results, challenging_results = [], [], []\n",
    "    \n",
    "    batch_size = 10\n",
    "    for i, content in enumerate(contents):\n",
    "        if content[\"difficulty\"] == \"simple\":\n",
    "            simple_results.append(exec_results[i])\n",
    "\n",
    "        if content[\"difficulty\"] == \"moderate\":\n",
    "            moderate_results.append(exec_results[i])\n",
    "\n",
    "        if content[\"difficulty\"] == \"challenging\":\n",
    "            try:\n",
    "                challenging_results.append(exec_results[i])\n",
    "            except:\n",
    "                print(i)\n",
    "\n",
    "        # Process every batch_size examples\n",
    "        if (i + 1) % batch_size == 0 or i + 1 == num_queries:\n",
    "            simple_acc = sum([res[\"res\"] for res in simple_results]) / len(simple_results) if simple_results else 0\n",
    "            moderate_acc = sum([res[\"res\"] for res in moderate_results]) / len(moderate_results) if moderate_results else 0\n",
    "            challenging_acc = sum([res[\"res\"] for res in challenging_results]) / len(challenging_results) if challenging_results else 0\n",
    "            all_acc = sum([res[\"res\"] for res in exec_results[:i+1]]) / (i + 1)\n",
    "\n",
    "            count_lists = [\n",
    "                len(simple_results),\n",
    "                len(moderate_results),\n",
    "                len(challenging_results),\n",
    "                i + 1,\n",
    "            ]\n",
    "\n",
    "            score_lists = [\n",
    "                simple_acc * 100,\n",
    "                moderate_acc * 100,\n",
    "                challenging_acc * 100,\n",
    "                all_acc * 100,\n",
    "            ]\n",
    "\n",
    "            save_data(i + 1, results_path, score_lists, count_lists, metric)\n",
    "\n",
    "def save_data(idx, results_path, score_lists, count_lists, metric):\n",
    "    levels = [\"simple\", \"moderate\", \"challenging\", \"total\"]\n",
    "    \n",
    "    with open(results_path, 'a') as file:\n",
    "        file.write(f\"Result Index: {idx}\\n\")\n",
    "        file.write(\"{:20} {:20} {:20} {:20} {:20}\\n\".format(\"\", *levels))\n",
    "        file.write(\"{:20} {:<20} {:<20} {:<20} {:<20}\\n\".format(\"count\", *count_lists))\n",
    "\n",
    "        file.write(\n",
    "            f\"======================================    {metric}    =====================================\\n\"\n",
    "        )\n",
    "\n",
    "        formatted_scores = [\n",
    "            f\"{score:.2f}\" if score is not None else \"N/A\" for score in score_lists\n",
    "        ]\n",
    "        file.write(\"{:20} {:<20} {:<20} {:<20} {:<20}\\n\".format(metric, *formatted_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistake_examples = []\n",
    "\n",
    "mistake_prompt = '\\n\\n'.join(\n",
    "    [\n",
    "        f\"example{index+1}: {{\\n\" + \n",
    "        '\\n'.join([f\"{key}: {value}\" for key, value in example.items() if key != 'difficulty']) + \n",
    "        \"\\n}\"\n",
    "        for index, example in enumerate(mistake_examples)\n",
    "    ]\n",
    ")\n",
    "assert mistake_prompt!=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_sql = \"\"\n",
    "assert predicted_sql != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "                base_url=\"http://localhost:28083/v1/\",\n",
    "                api_key=\"Empty\",\n",
    "            )\n",
    "instruction = \"Hi. \"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"{0}：{1}\".format(instruction,input)},\n",
    "]\n",
    "       \n",
    "completion = client.chat.completions.create(\n",
    "    model=\"Qwen2-57B-A14B-Instruct-GPTQ-Int4\",\n",
    "    messages=messages,\n",
    "    stream=False, #设置是否流式输出\n",
    "    #max_tokens=1000,\n",
    "    top_p=1\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {str(i): chr(64 + i) for i in range(1, 27)}\n",
    "ans = list()\n",
    "\n",
    "def dfs(i,s, pre):\n",
    "    if i >= len(s):\n",
    "        ans.append(pre)\n",
    "        return\n",
    "    if i < len(s):\n",
    "        dfs(i+1,s,pre+dic[s[i]])\n",
    "    if i + 1 < len(s) and int(s[i:i+2])<=26:\n",
    "        dfs(i+2,s,pre+dic[s[i:i+2]])\n",
    "\n",
    "s = '121'\n",
    "\n",
    "dfs(0,s,\"\")\n",
    "print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_ways(s: str) -> list:\n",
    "    n = len(s)\n",
    "    dp = [[] for _ in range(n + 1)]\n",
    "    dp[n] = [\"\"]\n",
    "\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        if s[i] == \"0\":\n",
    "            continue\n",
    "\n",
    "        # 单字符解码W\n",
    "        for tail in dp[i + 1]:\n",
    "            dp[i].append(chr(int(s[i]) + ord('A') - 1) + tail)\n",
    "\n",
    "        # 双字符解码\n",
    "        if i + 1 < n and 10 <= int(s[i:i + 2]) <= 26:\n",
    "            for tail in dp[i + 2]:\n",
    "                dp[i].append(chr(int(s[i:i + 2]) + ord('A') - 1) + tail)\n",
    "\n",
    "    return dp[0]\n",
    "\n",
    "# 示例用法\n",
    "input_str = \"121\"\n",
    "print(decode_ways(input_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qwen2_generation(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(\n",
    "      base_url=\"http://localhost:28083/v1/\",\n",
    "      api_key=\"Empty\",\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen2-57B-A14B-Instruct-GPTQ-Int4\",\n",
    "        messages=messages,\n",
    "        stream=False,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "qwen2_generation('1+1=?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mismatched_votes(input_string):\n",
    "    # 分割输入字符串为单独的结果\n",
    "    results = input_string.split('vote')\n",
    "    \n",
    "    mismatch_count = 0\n",
    "    for result in results:\n",
    "        \n",
    "        if 'res: 1' in result and not ('res1: 1' in result and 'res2: 1' in result and 'res3: 1' in result):\n",
    "            print(result)\n",
    "            mismatch_count += 1\n",
    "        elif 'res: 0' in result and not ('res1: 0' in result and 'res2: 0' in result and 'res3: 0' in result):\n",
    "            print(result)\n",
    "            mismatch_count += 1\n",
    "    \n",
    "    return mismatch_count\n",
    "\n",
    "input_string = \"\"\n",
    "with open('/data/qqt/1615_c/text-to-sql/bird_minidev/llm/result.txt',\"r\") as file:\n",
    "    input_string = file.readline()\n",
    "\n",
    "\n",
    "print(count_mismatched_votes(input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
