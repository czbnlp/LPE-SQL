{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 65068.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "15\n",
      "4\n",
      "95\n",
      "36\n",
      "32\n",
      "29\n",
      "18\n",
      "14\n",
      "87\n",
      "70\n",
      "12\n",
      "76\n",
      "55\n",
      "5\n",
      "98\n",
      "89\n",
      "28\n",
      "30\n",
      "65\n",
      "78\n",
      "85\n",
      "72\n",
      "26\n",
      "90\n",
      "54\n",
      "94\n",
      "58\n",
      "96\n",
      "1\n",
      "21\n",
      "91\n",
      "44\n",
      "80\n",
      "20\n",
      "83\n",
      "68\n",
      "7\n",
      "6\n",
      "25\n",
      "63\n",
      "23\n",
      "69\n",
      "59\n",
      "39\n",
      "17\n",
      "52\n",
      "3\n",
      "47\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假设 question_list 已经定义好了\n",
    "question_list = list(range(1, 101)) \n",
    "\n",
    "# 设置随机种子\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "# 定义子集的大小\n",
    "subset_size = 50\n",
    "\n",
    "# 从 question_list 中随机选择一个子集\n",
    "random_subset = random.sample(question_list, subset_size)\n",
    "\n",
    "# 使用 tqdm 显示进度条进行迭代\n",
    "for i in tqdm(random_subset):\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json(dir):\n",
    "    with open(dir, \"r\") as j:\n",
    "        contents = json.loads(j.read())\n",
    "    return contents\n",
    "\n",
    "def compute_acc_by_diff(exec_results, diff_json_path, results_path, metric=\"EX\"):\n",
    "    num_queries = len(exec_results)\n",
    "    contents = load_json(diff_json_path)\n",
    "    simple_results, moderate_results, challenging_results = [], [], []\n",
    "    \n",
    "    batch_size = 10\n",
    "    for i, content in enumerate(contents):\n",
    "        if content[\"difficulty\"] == \"simple\":\n",
    "            simple_results.append(exec_results[i])\n",
    "\n",
    "        if content[\"difficulty\"] == \"moderate\":\n",
    "            moderate_results.append(exec_results[i])\n",
    "\n",
    "        if content[\"difficulty\"] == \"challenging\":\n",
    "            try:\n",
    "                challenging_results.append(exec_results[i])\n",
    "            except:\n",
    "                print(i)\n",
    "\n",
    "        # Process every batch_size examples\n",
    "        if (i + 1) % batch_size == 0 or i + 1 == num_queries:\n",
    "            simple_acc = sum([res[\"res\"] for res in simple_results]) / len(simple_results) if simple_results else 0\n",
    "            moderate_acc = sum([res[\"res\"] for res in moderate_results]) / len(moderate_results) if moderate_results else 0\n",
    "            challenging_acc = sum([res[\"res\"] for res in challenging_results]) / len(challenging_results) if challenging_results else 0\n",
    "            all_acc = sum([res[\"res\"] for res in exec_results[:i+1]]) / (i + 1)\n",
    "\n",
    "            count_lists = [\n",
    "                len(simple_results),\n",
    "                len(moderate_results),\n",
    "                len(challenging_results),\n",
    "                i + 1,\n",
    "            ]\n",
    "\n",
    "            score_lists = [\n",
    "                simple_acc * 100,\n",
    "                moderate_acc * 100,\n",
    "                challenging_acc * 100,\n",
    "                all_acc * 100,\n",
    "            ]\n",
    "\n",
    "            save_data(i + 1, results_path, score_lists, count_lists, metric)\n",
    "\n",
    "def save_data(idx, results_path, score_lists, count_lists, metric):\n",
    "    levels = [\"simple\", \"moderate\", \"challenging\", \"total\"]\n",
    "    \n",
    "    with open(results_path, 'a') as file:\n",
    "        file.write(f\"Result Index: {idx}\\n\")\n",
    "        file.write(\"{:20} {:20} {:20} {:20} {:20}\\n\".format(\"\", *levels))\n",
    "        file.write(\"{:20} {:<20} {:<20} {:<20} {:<20}\\n\".format(\"count\", *count_lists))\n",
    "\n",
    "        file.write(\n",
    "            f\"======================================    {metric}    =====================================\\n\"\n",
    "        )\n",
    "\n",
    "        formatted_scores = [\n",
    "            f\"{score:.2f}\" if score is not None else \"N/A\" for score in score_lists\n",
    "        ]\n",
    "        file.write(\"{:20} {:<20} {:<20} {:<20} {:<20}\\n\".format(metric, *formatted_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m mistake_examples \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m mistake_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      4\u001b[0m     [\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ]\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mistake_prompt\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mistake_examples = []\n",
    "\n",
    "mistake_prompt = '\\n\\n'.join(\n",
    "    [\n",
    "        f\"example{index+1}: {{\\n\" + \n",
    "        '\\n'.join([f\"{key}: {value}\" for key, value in example.items() if key != 'difficulty']) + \n",
    "        \"\\n}\"\n",
    "        for index, example in enumerate(mistake_examples)\n",
    "    ]\n",
    ")\n",
    "assert mistake_prompt!=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m predicted_sql \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted_sql = \"\"\n",
    "assert predicted_sql != \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "                base_url=\"http://localhost:28083/v1/\",\n",
    "                api_key=\"Empty\",\n",
    "            )\n",
    "instruction = \"Hi. \"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"{0}：{1}\".format(instruction,input)},\n",
    "]\n",
    "       \n",
    "completion = client.chat.completions.create(\n",
    "    model=\"Qwen2-57B-A14B-Instruct-GPTQ-Int4\",\n",
    "    messages=messages,\n",
    "    stream=False, #设置是否流式输出\n",
    "    #max_tokens=1000,\n",
    "    top_p=1\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
